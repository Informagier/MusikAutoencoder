{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MusicAutoencoder\n",
    "\n",
    "This is the complete package:\n",
    "- read a song\n",
    "- train the model\n",
    "- compress it\n",
    "- decompress it\n",
    "- see a visual representation of the soundwave of the target and the original\n",
    "- write the result of it to your hard drive\n",
    "\n",
    "input song `input_song.flac`\n",
    "output song `result_song.flac`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrbxHLHMEUfm"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.losses as klosses\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.backend as k_backend\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "numpy.random.seed(4)\n",
    "random.seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YM7CDTH_IxZx",
    "outputId": "e5846ffc-18d6-4170-c334-0ba1c3e99bc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16647775245130559814\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15667858463253559945\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZ5OoGn9JwPR",
    "outputId": "8a2304cc-d3f5-4c85-8cf6-34885ffad061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11648640, 2), (1048576, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "song_data, samplerate = sf.read(\"input_song.flac\")\n",
    "\n",
    "song_segment = song_data[2**20: 2**21]\n",
    "(song_data.shape, song_segment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYdB4PtpV8Xc"
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "  \"\"\"normalizes the data and returns the parameters necessary to reconstruct the original\"\"\"\n",
    "  MIN = data.min()\n",
    "  data = data - MIN\n",
    "  DIV = data.max()\n",
    "  data = data / DIV\n",
    "  return (data, MIN, DIV)\n",
    "\n",
    "def denormalize(data_tuple):\n",
    "  \"\"\"reverts the normalization\"\"\"\n",
    "  (data, MIN, DIV) = data_tuple\n",
    "  return data * DIV + MIN\n",
    "\n",
    "def compression_exponent(factor):\n",
    "  \"\"\"returns the smalles n for 2^n > factor\"\"\"\n",
    "  return np.int_(np.ceil(np.log2(np.float64(factor))))\n",
    "\n",
    "def generate_data_for_training(song_data, compression_factor, window_width, stride, batch_size=8):\n",
    "  \"\"\"creates a generator, that returns batches of the training data\n",
    "  \n",
    "     returns the Generator and the number of steps per epoch\n",
    "  \"\"\"\n",
    "  comp_fac = 2 ** compression_exponent(compression_factor)\n",
    "  window_width += (comp_fac - (window_width % comp_fac)) % comp_fac\n",
    "  segment_indices = [(i, i + window_width) for i in range(0, song_data.shape[0] - window_width + stride, stride)]\n",
    "  def generator():\n",
    "    while True:\n",
    "      windows = map(lambda seg: song_data[seg[0] : seg[1]], segment_indices)\n",
    "      windows = map(lambda segment: np.concatenate([segment, np.zeros((window_width - segment.shape[0], segment.shape[1]))]), windows)\n",
    "      \n",
    "      while True:\n",
    "        targets = []\n",
    "        for i, w in zip(range(batch_size), windows):\n",
    "          targets.append(w.reshape((1, window_width, song_data.shape[1], 1)))\n",
    "        if len(targets) > 0:\n",
    "          targets = np.concatenate(targets)\n",
    "          yield (targets, targets)\n",
    "        else:\n",
    "          break\n",
    "\n",
    "  return (generator(), int(np.ceil(len(segment_indices) / batch_size))) \n",
    "  \n",
    "\n",
    "def predict(data, model, compression_factor, overlap = 2**16, segment_size = 2**18):\n",
    "  \"\"\"predicts the data the model\"\"\"\n",
    "  def transform_data_for_model(song_data):\n",
    "    \"\"\"transforms data to have a compatible size fopr the model\"\"\"\n",
    "    comp_fac = 2 ** compression_exponent(compression_factor)\n",
    "    padding_size = (comp_fac - (song_data.shape[0] % comp_fac)) % comp_fac\n",
    "    nd = np.concatenate([song_data, np.zeros((padding_size, song_data.shape[1]))])\n",
    "    nd = nd.reshape((1, nd.shape[0], nd.shape[1], 1))\n",
    "    return (nd, padding_size)\n",
    "  \"\"\"reverts the transform_data_for_model function\"\"\"\n",
    "  def transform_data_from_model(model_data, padding):\n",
    "    data = model_data[0][:model_data.shape[1] - padding]\n",
    "    return data.reshape((data.shape[0], data.shape[1]))\n",
    "\n",
    "  data_segments = [data[max(0, i - overlap):min(i + overlap + segment_size, data.shape[0])] for i in range(0, data.shape[0], segment_size)]\n",
    "  prepared_data = [transform_data_for_model(segment) for segment in data_segments]\n",
    "  model_input = [d[0] for d in prepared_data]\n",
    "  raw_prediction = [model.predict(i) for i in model_input]\n",
    "  prediction = [transform_data_from_model(tup[0], tup[1][1]) for tup in zip(raw_prediction, prepared_data)]\n",
    "  padding_free_prediction = [prediction[0][:segment_size]] + [pred[overlap : -overlap] for pred in prediction[1:-1]] + [prediction[-1][overlap:]]\n",
    "  return np.concatenate(padding_free_prediction)\n",
    "\n",
    "def evaluate(data, model, compression_factor, overlap = 2**16, segment_size = 2**18):\n",
    "  \"\"\"evaluates the model based on mse\"\"\"\n",
    "  pred = predict(data, model, compression_factor, overlap, segment_size)\n",
    "  return np.sum((pred - data) ** 2) / data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VI-ITKqS5TTP"
   },
   "outputs": [],
   "source": [
    "def create_encoder_decoder(data_shape, compression_factor, activation_en='elu', activation_de='elu', optimizer='adam', kernel_width_en=256, kernel_width_de=64, channel_count_en=16, channel_count_de=16, regularizer=None):\n",
    "  \"\"\"creates an encoder-decoder pair to be used in an autoencoder\"\"\"\n",
    "  acfun_in = activation_en\n",
    "  acfun_out = activation_de\n",
    "  layer_count = compression_exponent(compression_factor)\n",
    "\n",
    "  encoder = keras.Sequential(name = \"encoder\")\n",
    "  encoder.add(layers.Conv2D(channel_count_en, (kernel_width_en, data_shape[1]), activation='linear', padding='same', kernel_regularizer=regularizer, input_shape=data_shape))\n",
    "  for _ in range(layer_count // 2):\n",
    "    encoder.add(layers.Conv2D(channel_count_en, (kernel_width_en, data_shape[1]), strides = (4, 1), activation=acfun_in, padding='same', kernel_regularizer=regularizer))\n",
    "  if layer_count % 2 == 1:\n",
    "    encoder.add(layers.Conv2D(channel_count_en, (kernel_width_en, data_shape[1]), strides = (8, 1), activation=acfun_in, padding='same', kernel_regularizer=regularizer))\n",
    "  else:\n",
    "    encoder.add(layers.Conv2D(channel_count_en, (kernel_width_en, data_shape[1]), strides = (4, 1), activation=acfun_in, padding='same', kernel_regularizer=regularizer))\n",
    "\n",
    "  encoder.add(layers.Conv2D(4, (kernel_width_en, data_shape[1]), activation = 'linear', padding='same'))\n",
    "  \n",
    "  decoder = keras.Sequential(name = \"decoder\")\n",
    "  if layer_count % 2 == 1:\n",
    "    decoder.add(layers.Conv2DTranspose(channel_count_de, (kernel_width_de, data_shape[1]), strides=(8, 1), activation=acfun_out, padding='same'))\n",
    "  else:\n",
    "    decoder.add(layers.Conv2DTranspose(channel_count_de, (kernel_width_de, data_shape[1]), strides=(4, 1), activation=acfun_out, padding='same'))\n",
    "  for _ in range(layer_count // 2):\n",
    "    decoder.add(layers.Conv2DTranspose(channel_count_de, (kernel_width_de, data_shape[1]), strides=(4, 1), activation=acfun_out, padding='same'))\n",
    "  decoder.add(layers.Conv2D(1, (kernel_width_de, data_shape[1]), activation='linear', padding='same'))\n",
    "\n",
    "  return (encoder, decoder)\n",
    "\n",
    "def create_model(data_shape, activation_en='elu', activation_de='elu', optimizer='adam', kernel_width_en=256, kernel_width_de=64, channel_count_en=16, channel_count_de=16, compression_factor=8, loss='mse', regularizer = None):\n",
    "  \"\"\"creates an autoencoder\"\"\"\n",
    "  enc_dec = create_encoder_decoder(data_shape, compression_factor, activation_en, activation_de, optimizer, kernel_width_en, kernel_width_de, channel_count_en, channel_count_de)\n",
    "  model = keras.Sequential(name = \"autoencoder\")\n",
    "  model.add(enc_dec[0])\n",
    "  model.add(enc_dec[1])\n",
    "  model.compile(\n",
    "          loss=loss,\n",
    "          optimizer=optimizer,\n",
    "          metrics=[keras.metrics.MeanSquaredError()])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eX5KqAX2DrWx"
   },
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "(normalized_data, MIN, DIV) = normalize(song_data) \n",
    "(normalized_mock_data, MIN_mock, DIV_mock) = normalize(song_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtuXajtkIxaW",
    "outputId": "3f516d4c-5bfa-4d27-f8a3-73fb7d28c57d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11648640, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYV-6-OywTNU",
    "outputId": "ce93f9e8-8722-483c-830d-f4f027d9c2c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_factor = 4\n",
    "\n",
    "#create all combination of different hyperparameters on would want to test\n",
    "\n",
    "activation_ens = ['selu', 'tanh', 'softplus']\n",
    "activation_des = activation_ens\n",
    "channel_size_ens = [16, 32]\n",
    "channel_size_des = channel_size_ens\n",
    "kernel_size_ens = [32, 64]\n",
    "kernel_size_des = kernel_size_ens\n",
    "optimizers = ['adam']\n",
    "losses = ['mae', 'msle']\n",
    "\n",
    "\n",
    "parameters = list(itertools.product(activation_ens, activation_des, channel_size_ens, channel_size_des, kernel_size_ens, kernel_size_des, optimizers, losses))\n",
    "len(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8fnXTflXtH-",
    "outputId": "598175c4-be63-48ba-f334-d399e3aa8ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 16 steps\n",
      "Epoch 1/16\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.2088 - mean_squared_error: 0.0773\n",
      "Epoch 2/16\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.1058 - mean_squared_error: 0.0187\n",
      "Epoch 3/16\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0887 - mean_squared_error: 0.0133\n",
      "Epoch 4/16\n",
      "16/16 [==============================] - 51s 3s/step - loss: 0.0779 - mean_squared_error: 0.0104\n",
      "Epoch 5/16\n",
      "16/16 [==============================] - 50s 3s/step - loss: 0.0707 - mean_squared_error: 0.0086\n",
      "Epoch 6/16\n",
      "16/16 [==============================] - 51s 3s/step - loss: 0.0610 - mean_squared_error: 0.0067\n",
      "Epoch 7/16\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0555 - mean_squared_error: 0.0056\n",
      "Epoch 8/16\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.0538 - mean_squared_error: 0.0053\n",
      "Epoch 9/16\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.0540 - mean_squared_error: 0.0052\n",
      "Epoch 10/16\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.0588 - mean_squared_error: 0.0059\n",
      "Epoch 11/16\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0524 - mean_squared_error: 0.0050\n",
      "Epoch 12/16\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0477 - mean_squared_error: 0.0043\n",
      "Epoch 13/16\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0484 - mean_squared_error: 0.0044\n",
      "Epoch 14/16\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.0501 - mean_squared_error: 0.0046\n",
      "Epoch 15/16\n",
      "16/16 [==============================] - 44s 3s/step - loss: 0.0451 - mean_squared_error: 0.0040\n",
      "Epoch 16/16\n",
      "16/16 [==============================] - 44s 3s/step - loss: 0.0455 - mean_squared_error: 0.0040\n",
      "0 \tneeded 767.7499876022339 seconds\t ('selu', 'selu', 16, 16, 32, 32, 'adam', 'mae') \tloss: 0.0038651970906773843\n"
     ]
    }
   ],
   "source": [
    "def test_model(params, data, compression_factor):\n",
    "  \"\"\"trains and evaluates a combination of hyperparameters\"\"\"\n",
    "  (activation_en,\n",
    "   activation_de,\n",
    "   channel_size_en,\n",
    "   channel_size_de,\n",
    "   kernel_size_en,\n",
    "   kernel_size_de,\n",
    "   optimizer,\n",
    "   loss) = params\n",
    "\n",
    "  model = create_model((None, data.shape[1], 1),\n",
    "                            activation_en = activation_en,\n",
    "                            activation_de = activation_de,\n",
    "                            optimizer = optimizer,\n",
    "                            kernel_width_en = kernel_size_en,\n",
    "                            kernel_width_de = kernel_size_de,\n",
    "                            channel_count_en = channel_size_en,\n",
    "                            channel_count_de = channel_size_de,\n",
    "                            compression_factor = compression_factor,\n",
    "                            loss = loss)\n",
    "  \n",
    "  data_generator, steps_per_epoch = generate_data_for_training(data, compression_factor, 2 ** 16, 2 ** 14, 4)\n",
    "  history = model.fit(data_generator, steps_per_epoch = steps_per_epoch, epochs = 16, verbose = 0)\n",
    "\n",
    "  return (model, history)\n",
    "#iterate through all combinations of hyperparameters  \n",
    "results = []\n",
    "for i, params in enumerate(parameters):\n",
    "  start = time.time()\n",
    "  model, history = test_model(params, normalized_mock_data, compression_factor)\n",
    "  loss = evaluate(normalized_mock_data, model, compression_factor)\n",
    "  results.append((history, params, loss))\n",
    "  print(i, \"\\tneeded\", time.time() - start, \"seconds\\t\", params, \"\\tloss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxO-1dDZLtrN",
    "outputId": "c7ac5a3a-cdb1-44cb-bc52-4372ac01964f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tensorflow.python.keras.callbacks.History object at 0x7f7720412610>, ('selu', 'selu', 16, 16, 32, 32, 'adam', 'mae'), 0.0038651970906773843)\n"
     ]
    }
   ],
   "source": [
    "#sort the hyperparameters by their loss\n",
    "results = sorted(results, key=lambda x: x[2])\n",
    "for res in results:\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30n8Wc_XRYP0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Sequential)         (None, None, 2, 4)        37940     \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         (None, None, 2, 1)        21537     \n",
      "=================================================================\n",
      "Total params: 59,477\n",
      "Trainable params: 59,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create a model with the best found hyperparameter combination\n",
    "(activation_en,\n",
    " activation_de,\n",
    " channel_size_en,\n",
    " channel_size_de,\n",
    " kernel_size_en,\n",
    " kernel_size_de,\n",
    " optimizer,\n",
    " loss) = results[0][1]\n",
    "\n",
    "model = create_model((None, normalized_mock_data.shape[1], 1),\n",
    "                            activation_en = activation_en,\n",
    "                            activation_de = activation_de,\n",
    "                            optimizer = optimizer,\n",
    "                            kernel_width_en = kernel_size_en,\n",
    "                            kernel_width_de = kernel_size_de,\n",
    "                            channel_count_en = channel_size_en,\n",
    "                            channel_count_de = channel_size_de,\n",
    "                            compression_factor = compression_factor,\n",
    "                            loss = loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7H82eX-I6OM9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 44 steps\n",
      "Epoch 1/16\n",
      "44/44 [==============================] - 576s 13s/step - loss: 0.1519 - mean_squared_error: 0.0460\n",
      "Epoch 2/16\n",
      "44/44 [==============================] - 538s 12s/step - loss: 0.0911 - mean_squared_error: 0.0141\n",
      "Epoch 3/16\n",
      "44/44 [==============================] - 556s 13s/step - loss: 0.0694 - mean_squared_error: 0.0084\n",
      "Epoch 4/16\n",
      "44/44 [==============================] - 557s 13s/step - loss: 0.0563 - mean_squared_error: 0.0056\n",
      "Epoch 5/16\n",
      "44/44 [==============================] - 534s 12s/step - loss: 0.0567 - mean_squared_error: 0.0057\n",
      "Epoch 6/16\n",
      "44/44 [==============================] - 536s 12s/step - loss: 0.0531 - mean_squared_error: 0.0051\n",
      "Epoch 7/16\n",
      "44/44 [==============================] - 526s 12s/step - loss: 0.0484 - mean_squared_error: 0.0044\n",
      "Epoch 8/16\n",
      "44/44 [==============================] - 526s 12s/step - loss: 0.0491 - mean_squared_error: 0.0045\n",
      "Epoch 9/16\n",
      "44/44 [==============================] - 526s 12s/step - loss: 0.0458 - mean_squared_error: 0.0040\n",
      "Epoch 10/16\n",
      "44/44 [==============================] - 525s 12s/step - loss: 0.0464 - mean_squared_error: 0.0040\n",
      "Epoch 11/16\n",
      "44/44 [==============================] - 526s 12s/step - loss: 0.0432 - mean_squared_error: 0.0036\n",
      "Epoch 12/16\n",
      "44/44 [==============================] - 524s 12s/step - loss: 0.0443 - mean_squared_error: 0.0037\n",
      "Epoch 13/16\n",
      "44/44 [==============================] - 1142s 26s/step - loss: 0.0409 - mean_squared_error: 0.0033\n",
      "Epoch 14/16\n",
      "44/44 [==============================] - 525s 12s/step - loss: 0.0417 - mean_squared_error: 0.0034\n",
      "Epoch 15/16\n",
      "44/44 [==============================] - 526s 12s/step - loss: 0.0396 - mean_squared_error: 0.0031\n",
      "Epoch 16/16\n",
      "44/44 [==============================] - 526s 12s/step - loss: 0.0397 - mean_squared_error: 0.0031\n",
      "Train for 11 steps\n",
      "Epoch 1/48\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "# first on smaller windows, then on larger ones for speed\n",
    "data_generator_small, steps_per_epoch_small = generate_data_for_training(normalized_data, compression_factor, 2 ** 18, 2 ** 16, 4)\n",
    "data_generator_big, steps_per_epoch_big = generate_data_for_training(normalized_data, compression_factor, 2 ** 20, 2 ** 18, 4)\n",
    "history_small = model.fit_generator(data_generator_small, steps_per_epoch = steps_per_epoch_small, epochs = 16)\n",
    "history_big = model.fit_generator(data_generator_big, steps_per_epoch = steps_per_epoch_big, epochs = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31CyyesvrucR"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSUHmwlJ7RZ5"
   },
   "outputs": [],
   "source": [
    "#transform the predicted data back into its original featurespace\n",
    "result = denormalize((predict(normalized_mock_data, model, compression_factor), MIN_mock, DIV_mock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrEeqJsEc2EG"
   },
   "outputs": [],
   "source": [
    "abs_diff = np.sum(np.abs(result - normalized_mock_data))\n",
    "rel_diff = abs_diff / result.size\n",
    "(abs_diff, rel_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itQxRZUfdCmX"
   },
   "outputs": [],
   "source": [
    "#plot an extract of the sound file\n",
    "plt.figure(figsize=(160, 9))\n",
    "offset = 100_000\n",
    "plt.plot(result[offset:offset + 2**12, :1], label='Prediction')\n",
    "plt.plot(song_segment[offset:offset + 2**12, :1], label='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9_Dz-eRdRPT"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0042166b377b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_PREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"result_song.flac\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sf' is not defined"
     ]
    }
   ],
   "source": [
    "sf.write(\"result_song.flac\", result, samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3TwGpvT0Q-D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osXu1pZcIxbO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNNfikGjIxbT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkgaqd32IxbX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MusicAutoencoder3Kopie.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
